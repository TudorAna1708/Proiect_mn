import streamlit as st
import joblib
import os
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity

# CONFIGURARE
FILE_DATASET = 'dataset.txt'
FILE_VECTORIZER = 'bot_vectorizer.pkl'
FILE_MODEL = 'bot_svd_model.pkl'
FILE_DATA = 'bot_data.pkl'

st.set_page_config(page_title="AI Chatbot All-in-One", page_icon="ğŸ¤–")


# 1. FUNCÈšIA DE ANTRENARE
def antreneaza_model():
    """CiteÈ™te dataset.txt È™i regenereazÄƒ fiÈ™ierele .pkl"""
    if not os.path.exists(FILE_DATASET):
        return False, "FiÈ™ierul dataset.txt lipseÈ™te!"

    # Citire date
    questions = []
    answers = []

    try:
        with open(FILE_DATASET, 'r', encoding='utf-8') as f:
            for linie in f:
                if '|' in linie and linie.strip():
                    parts = linie.split('|')
                    questions.append(parts[0].strip())
                    answers.append(parts[1].strip())
    except Exception as e:
        return False, f"Eroare la citire: {e}"

    if len(questions) == 0:
        return False, "Dataset-ul este gol!"

    # Procesare
    # Folosim setÄƒrile avansate (char_wb) pentru a recunoaÈ™te variaÈ›ii de cuvinte
    vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='char_wb', ngram_range=(3, 5))
    X = vectorizer.fit_transform(questions)

    # LogicÄƒ SVD vs TF-IDF simplu
    use_svd = False
    matrix_final = X
    lsa = None

    if len(questions) > 10:
        use_svd = True
        n_components = min(100, len(questions) - 1)
        lsa = TruncatedSVD(n_components=n_components)
        matrix_final = lsa.fit_transform(X)

    # Salvare pe disc
    joblib.dump(vectorizer, FILE_VECTORIZER)

    data_to_save = {'matrix': matrix_final, 'answers': answers, 'use_svd': use_svd}
    joblib.dump(data_to_save, FILE_DATA)

    if use_svd:
        joblib.dump(lsa, FILE_MODEL)

    return True, f"Antrenare reuÈ™itÄƒ pe {len(questions)} exemple!"


# 2. FUNCÈšIA DE ÃNCÄ‚RCARE (Cached)
@st.cache_resource
def incarca_resurse():
    """ÃncarcÄƒ modelele Ã®n memorie. DacÄƒ nu existÄƒ, le antreneazÄƒ Ã®ntÃ¢i."""

    # VerificÄƒm dacÄƒ fiÈ™ierele existÄƒ. DacÄƒ nu, antrenÄƒm acum.
    if not os.path.exists(FILE_VECTORIZER) or not os.path.exists(FILE_DATA):
        success, msg = antreneaza_model()
        if not success:
            return None, None, None, None, None  # Eroare criticÄƒ

    # ÃncÄƒrcÄƒm resursele
    vectorizer = joblib.load(FILE_VECTORIZER)
    data = joblib.load(FILE_DATA)
    matrix_final = data['matrix']
    answers = data['answers']
    use_svd = data.get('use_svd', False)

    lsa = None
    if use_svd:
        lsa = joblib.load(FILE_MODEL)

    return vectorizer, lsa, matrix_final, answers, use_svd

# 3. LOGICA DE RÄ‚SPUNS
def get_best_response(user_input, vectorizer, lsa, matrix_final, answers, use_svd):
    try:
        user_vec = vectorizer.transform([user_input])

        if use_svd:
            query_vec = lsa.transform(user_vec)
        else:
            query_vec = user_vec

        similarities = cosine_similarity(query_vec, matrix_final)[0]
        best_idx = np.argmax(similarities)
        best_score = similarities[best_idx]

        if best_score > 0.7:
            return answers[best_idx]
        else:
            return "Nu sunt sigur cÄƒ am Ã®nÈ›eles. PoÈ›i reformula?"
    except Exception:
        return "Eroare la procesarea rÄƒspunsului."


# 4. INTERFAÈšA GRAFICÄ‚ (Streamlit)

# Sidebar pentru control (Re-antrenare)
with st.sidebar:
    st.header("âš™ï¸ Panou Control")
    st.info("ModificÄƒ 'dataset.txt' È™i apasÄƒ butonul de mai jos.")

    if st.button("ğŸ”„ Re-antreneazÄƒ Modelul"):
        with st.spinner("Se Ã®nvaÈ›Äƒ noile date..."):
            # È˜tergem cache-ul vechi
            st.cache_resource.clear()
            # RulÄƒm antrenarea
            ok, mesaj = antreneaza_model()
            if ok:
                st.success(mesaj)
            else:
                st.error(mesaj)
            # ReÃ®ncÄƒrcÄƒm pagina
            st.rerun()

st.title("ğŸ¤– Asistent Inteligent")

# ÃncÄƒrcÄƒm "Creierul"
vectorizer, lsa, matrix_final, answers, use_svd = incarca_resurse()

if vectorizer is None:
    st.error("Eroare CriticÄƒ: Nu pot Ã®ncÄƒrca sau antrena modelul. VerificÄƒ `dataset.txt`.")
    st.stop()

# Gestionarea istoricului de chat
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Salut! Cu ce te pot ajuta?"}]

# AfiÈ™area mesajelor
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input utilizator
if prompt := st.chat_input("Scrie mesajul tÄƒu..."):
    # 1. AfiÈ™Äƒm user
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. CalculÄƒm rÄƒspuns
    raspuns = get_best_response(prompt, vectorizer, lsa, matrix_final, answers, use_svd)

    # 3. AfiÈ™Äƒm bot
    st.session_state.messages.append({"role": "assistant", "content": raspuns})
    with st.chat_message("assistant"):
        st.markdown(raspuns)